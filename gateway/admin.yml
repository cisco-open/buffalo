# Enterprise LLM Gateway - Admin Configurable Policy 
 
# Here, admins can specify the settings for their Gateway. 
# Currently-implemented features are detailed below. 


supported_models: 
- "gpt-3.5"
- "dolly-3b"
api_keys: 
  "gpt-3.5": "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"

path_to_doc: "docs/"
show_docs: True 

# Section 01) Prompt Layer 

use_prompt : True # HAS NOT BEEN ADDED YET 
user_model_choice: True # HAS NOT BEEN ADDED YET 


# Section 02) Cache Layer 

use_cache: True # HAS NOT BEEN ADDED YET 
cache_thresh: "auto"
cache_default: 0.8 


# Section 03) Exfiltration 

use_exfiltration: True # HAS NOT BEEN ADDED YET 
sensitive_info:
  - "employee_info.txt" 
  - "secret_project.txt"


# Section 04) Verification 

fact_threshold: 0.9 
fact_model_name: "lighteternal/fact-or-opinion-xlmr-el"
rel_threshold: 0.66

explainable_verification: True  # HAS NOT BEEN ADDED YET 
rel_extractor_default: "openie" # HAS NOT BEEN ADDED YET 
